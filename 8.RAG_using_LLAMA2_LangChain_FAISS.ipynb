{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25a86c0-d447-44c1-b19b-dad0b8e930a9",
   "metadata": {},
   "source": [
    "### LLAMA2 + RAG + FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3687cfbf-e714-4749-b68d-b533604e4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import textwrap\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe2097d-22bd-4ebf-b4cf-51b84bdb821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect your own PDF\n",
    "loader = UnstructuredFileLoader('dataset/nlp_2024.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b021fb-b5af-4942-bc0e-f10b248bebb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3089, which is longer than the specified 1000\n",
      "Created a chunk of size 1963, which is longer than the specified 1000\n",
      "Created a chunk of size 3123, which is longer than the specified 1000\n",
      "Created a chunk of size 2798, which is longer than the specified 1000\n",
      "Created a chunk of size 1040, which is longer than the specified 1000\n",
      "Created a chunk of size 1944, which is longer than the specified 1000\n",
      "Created a chunk of size 3109, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter=CharacterTextSplitter(separator='\\n',\n",
    "                                    chunk_size=1000,\n",
    "                                    chunk_overlap=50)\n",
    "text_chunks=text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c83be34-2423-46e1-86ad-827ef5afb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='/home/jomondal/experiments/mywork/pretrained_models/all-MiniLM-L6-v2',model_kwargs={'device': 'cuda'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a1f9e5-194b-47b3-a742-7a8ab168922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c5bdc2a-1d3c-4e96-8401-31c621e5d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/home/jomondal/experiments/mywork/pretrained_models/Llama-2-7b-chat-hf\"\n",
    "device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e7fc32-a9dd-4b84-bf03-214eb8b5188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae1905207984749adbc48f1ff2ddd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_compute_dtype=compute_dtype\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    quantization_config=bnb_config,\n",
    "    \n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc18786-d1fa-4d42-aeed-db3067c4a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 1024,\n",
    "                do_sample=True,\n",
    "                top_k=10,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc5eeba-5dca-4eab-a1e5-e6282368377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about chatGPT?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63e9c98-86dd-4e38-b6c9-000f9f7bc4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Tell me about chatGPT?\\n everybody is talking about it, but I don\\'t know much about it. Can you explain it to me?\\n\\nSure, I\\'d be happy to explain! ChatGPT is a type of artificial intelligence (AI) model that is designed to generate human-like text responses to user input. It was created by the company OpenAI and was first released in 2018.\\n\\nChatGPT is based on a type of AI called a transformer, which is a type of neural network that is particularly well-suited for natural language processing tasks. The model is trained on a large dataset of text from the internet, and it can generate text that is often indistinguishable from human-written text.\\n\\nOne of the key features of ChatGPT is its ability to engage in conversation with users. Users can input a prompt or question, and the model will generate a response based on the context of the conversation. For example, if a user asks ChatGPT \"What is your favorite hobby?\", the model might respond with \"I enjoy playing video games in my free time.\"\\n\\nChatGPT has a wide range of applications, including but not limited to:\\n\\n1. Customer service: ChatGPT can be used to provide automated customer support, answering common questions and responding to customer inquiries.\\n2. Language translation: ChatGPT can be used to translate text from one language to another, allowing users to communicate with people who speak different languages.\\n3. Content generation: ChatGPT can be used to generate content, such as articles, blog posts, and social media updates.\\n4. Conversational AI: ChatGPT can be used to build conversational AI systems, such as virtual assistants and chatbots.\\n5. Research: ChatGPT can be used for a variety of research tasks, such as analyzing text data, generating text summaries, and improving language understanding.\\n\\nOverall, ChatGPT is a powerful tool that has the potential to revolutionize the way we interact with technology. Its ability to generate human-like text responses makes it an ideal candidate for a wide range of applications, from customer service to content generation.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b887f23c-2ab2-4c82-a77f-0e166713d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =  RetrievalQA.from_chain_type(llm=llm, chain_type = \"stuff\",return_source_documents=True, retriever=vectorstore.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72b90cb-677f-4627-a0ff-b2af2f661816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jomondal/experiments/mywork/venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ChatGPT is an AI chatbot developed by OpenAI and backed by Microsoft. It uses deep learning to generate human-like responses to natural language inputs provided through a simple chatbot user interface. ChatGPT can understand and respond to a wide range of questions and topics, from simple queries to more complex discussions. It can also be used for a variety of applications, such as customer service, language translation, and content creation. While ChatGPT is impressive, it is important to\\nnote that it is not perfect and may sometimes provide biased or incorrect answers. Therefore, it is important to use ChatGPT responsibly and critically evaluate the information it provides.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=chain({\"query\": prompt}, return_only_outputs=True)\n",
    "wrapped_text = textwrap.fill(result['result'], width=500)\n",
    "wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d40bac-2257-4988-8b4b-98f4da3de294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
