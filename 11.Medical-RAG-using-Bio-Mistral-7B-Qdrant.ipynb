{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bedf7b3-e3d5-4e65-a982-e6169ab9475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,BitsAndBytesConfig,pipeline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971f5c1-f222-4899-8f1f-6c0fd99ae648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f585ede-5ff3-4812-8fc5-3e0c218b20ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n",
      "Using GPU:  NVIDIA A100-SXM4-40GB\n",
      "Memory Usage: \n",
      "Allocated:  5.1 GB\n",
      "Cached:  11.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    print('Using GPU: ', torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage: ')\n",
    "    print('Allocated: ', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached: ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "641efb09-5d8b-4634-9666-7687fb34169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84639fba-f4e4-4b26-aa5b-cbda35001219",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f8e406-d183-4a57-995b-33e2452e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id =\"../pretrained_models/BioMistral-7B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,quantization_config=bnb_config,do_sample=True,device_map = \"auto\")\n",
    "\n",
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "875fc4c5-24d8-4b7a-a34b-f9850b67cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> tell me about covid? in 50 words or less.( 6)so you are saying covid is still around?( 7)yes.( 8)its still around?( 9)not really( 10)not really?( 11)what do you mean not really? so you saying that covid is not really here?( 12)im saying there still 1000 people die from it each day.( 13)is there 1000?( 14)covid is really in america?( 15)what do you mean covid is in america?( 16)what did you mean by that? like in 2021?( 17)i told you this year,( 18)there is new variant around?( 19)what are the variants?( 20)new variant? what are the new variants?( 21)what do you mean covid is still around?( 22)what do you mean?( 23)how many people get vaccinated?( 24)what do you mean?( 25)do you vaccinate?( 26)what you talk about?( 27)you talking about vaccination?( 28)new variant covid?( 29)what do you mean new variant?( 30)what means new variant? do you mean new vaccine?( 31)you are saying there is\n"
     ]
    }
   ],
   "source": [
    "prompt = \"tell me about covid? in 50 words\"\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=300, do_sample=True,pad_token_id=tokenizer.eos_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "print(decoded.replace('\\\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4446f0aa-544f-4fd7-b892-eec0c941ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ") model_name='../pretrained_models/pubmedbert-base-embeddings' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "emb_model_name = \"../pretrained_models/pubmedbert-base-embeddings\"\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=emb_model_name)\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f540ab-7e41-4a25-a533-69359e96c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='relation to exercise prescription, management of complications and palliative care.\\n\\nThroughout our short course we will emphasise the importance of effective communication\\n\\nwith MDT, patients and their families to ensure optimum care is provided.\\n\\nWe trust that the following short-course and information booklet will add to your knowledge\\n\\naround the area of breast cancer care and enhance your skills as a developing clinician.\\n\\nJohn Allen, Clodagh Burrell, Clara Caplice, Deirdre Collins, Patrick McGreal & Joanne Purcell.\\n\\nthis\\n\\n2\\n\\nLearning Objectives\\n\\n1. To describe the pathophysiology of cancer with a primary focus on breast cancer.' metadata={'source': 'dataset/medical_data/Oncology.pdf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = DirectoryLoader('dataset/medical_data/', glob=\"**/*.pdf\", show_progress=True, loader_cls=UnstructuredFileLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=70)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(texts[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e9c29a7-8fb3-49ce-8fb2-41f2e9e5ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB Successfully Created!\n"
     ]
    }
   ],
   "source": [
    "qdrant = Qdrant.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"vector_db\"\n",
    ")\n",
    "\n",
    "print(\"Vector DB Successfully Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6678ba7a-9178-4d2b-b771-672f712a3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = qdrant.as_retriever(search_kwargs={\"k\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ef7ebab-c73c-4f2b-b11b-c4f12d17cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b93ebe2-30eb-4d57-b0aa-5277f85ef20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer. Answer must be detailed and well explained.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bf687f4-d950-4133-acb0-4bc67e46a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "664ab129-e0e9-49d4-8bac-b97473952fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e13594b4-edfb-4cc1-b2a8-9c3d33be9896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me about covid? in 50 words\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0918245-0d19-45af-9154-e2f3d5803fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: tell me about covid? in 50 words\n",
      "Covid is caused by SARS CoV-2 virus. It is transmitted through respiratory droplets and contact with infected people. Symptoms include fever, cough, shortness of breath, fatigue, muscle pain, sore throat, loss of taste and smell, diarrhea, nausea, vomiting, and conjunctivitis. Most people recover without treatment while some may need supportive care and antiviral therapy.\n"
     ]
    }
   ],
   "source": [
    "print (\"Question:\", response[\"question\"])\n",
    "print (response[\"text\"].replace('\\\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6fe25f-20a1-45e3-92b9-83203ad054b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba1051-2d90-4ee8-b7f9-0b24c9a6596c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
